# Postprocessing Playbook: PROJECT_CONTEXT Validation & Export

This postprocessing playbook defines validation steps and optional export formats for `PROJECT_CONTEXT.md` outputs generated by the Cartographer agent.

---

## Purpose

Postprocessing ensures that:
1. **Output Quality:** The generated PROJECT_CONTEXT.md meets all quality standards
2. **Template Compliance:** The output matches the selected template structure
3. **Machine Readability:** Optional JSON/YAML exports are generated for downstream tools
4. **Validation:** All evidence claims are verifiable and accurate

---

## When to Run Postprocessing

**Always run postprocessing when:**
- Generating PROJECT_CONTEXT for production use
- Feeding output to downstream RAG systems
- Validating before committing to repository
- Quality gates in CI/CD pipelines

**Optional postprocessing:**
- During development/testing (use spot checks instead)
- For throwaway/experimental analyses

---

## Validation Steps

### 1. Template Structure Validation

**Objective:** Ensure the output matches the selected template exactly.

**Steps:**

1. **Extract template sections:**
   ```bash
   # Extract all section headings from template
   grep -E '^#{1,3}\s' outputs/output-project-context-standard.md > expected-sections.txt

   # Extract all section headings from generated output
   grep -E '^#{1,3}\s' PROJECT_CONTEXT.md > actual-sections.txt

   # Compare
   diff expected-sections.txt actual-sections.txt
   ```

2. **Verify section tags:**
   ```bash
   # Check that all [SECTION:*] tags from template are present
   grep -o '\[SECTION:[A-Z_]*\]' outputs/output-project-context-standard.md | sort > expected-tags.txt
   grep -o '\[SECTION:[A-Z_]*\]' PROJECT_CONTEXT.md | sort > actual-tags.txt
   diff expected-tags.txt actual-tags.txt
   ```

3. **Check heading hierarchy:**
   - Verify # (h1) is only used once for title
   - Verify ## (h2) for main sections
   - Verify ### (h3) for subsections
   - No orphaned sections

**Pass Criteria:**
- ✅ All template sections present
- ✅ Section tags preserved
- ✅ Heading hierarchy correct
- ✅ No extra sections added

---

### 2. Content Quality Validation

**Objective:** Ensure content meets quality standards.

**Steps:**

1. **Check for placeholder text:**
   ```bash
   # Search for common placeholder patterns
   grep -i '\[TODO\]' PROJECT_CONTEXT.md
   grep -i '\[TBD\]' PROJECT_CONTEXT.md
   grep -i 'PLACEHOLDER' PROJECT_CONTEXT.md
   grep -i 'FIXME' PROJECT_CONTEXT.md
   ```

2. **Verify evidence-based claims:**
   - All file paths should be verifiable
   - Versions should be exact (not "latest" or "unknown")
   - Counts should be numeric (not "many" or "several")

3. **Check for speculation:**
   ```bash
   # Search for speculative language (should be minimal)
   grep -i 'probably\|likely\|might be\|could be\|perhaps' PROJECT_CONTEXT.md
   ```

4. **Validate code blocks:**
   ```bash
   # Check that code blocks have language specifiers
   grep -E '^```[[:space:]]*$' PROJECT_CONTEXT.md
   # Should return empty (all code blocks should have language: ```javascript, ```python, etc.)
   ```

**Pass Criteria:**
- ✅ No placeholder text
- ✅ All file paths exist (spot check)
- ✅ Versions are specific
- ✅ Minimal speculation
- ✅ All code blocks have language tags

---

### 3. Security Validation

**Objective:** Ensure no secrets or sensitive data leaked into output.

**Steps:**

1. **Search for common secret patterns:**
   ```bash
   # API keys
   grep -iE '(api[_-]?key|apikey|api_secret).*[:=].{10,}' PROJECT_CONTEXT.md

   # Tokens
   grep -iE '(token|jwt|bearer).*[:=].{20,}' PROJECT_CONTEXT.md

   # Passwords
   grep -iE '(password|passwd|pwd).*[:=].{5,}' PROJECT_CONTEXT.md

   # Connection strings
   grep -iE '(postgres|mysql|mongodb)://[^/]+:[^@]+@' PROJECT_CONTEXT.md

   # Private keys
   grep -i 'BEGIN.*PRIVATE KEY' PROJECT_CONTEXT.md
   ```

2. **Check for internal hostnames/IPs:**
   ```bash
   # Look for private IP ranges
   grep -E '(10\.|172\.(1[6-9]|2[0-9]|3[01])\.|192\.168\.)' PROJECT_CONTEXT.md

   # Look for internal domain patterns
   grep -E '\.internal\.|\.local\.|\.corp\.' PROJECT_CONTEXT.md
   ```

3. **Verify redaction compliance:**
   - If `specialConstraints` includes redaction rules, verify they were followed
   - Check that sensitive values are replaced with placeholders like `[REDACTED]` or `$SECRET_NAME`

**Pass Criteria:**
- ✅ No API keys, tokens, or passwords
- ✅ No database credentials
- ✅ No private keys
- ✅ Internal hostnames redacted (if required)
- ✅ Redaction rules followed

---

### 4. Markdown Validation

**Objective:** Ensure valid, well-formed Markdown.

**Steps:**

1. **Lint Markdown:**
   ```bash
   # Using markdownlint (if available)
   markdownlint PROJECT_CONTEXT.md

   # Or use online validator
   # https://www.markdownlint.com/
   ```

2. **Check table formatting:**
   ```bash
   # Tables should have proper delimiters
   grep -E '^\|.*\|$' PROJECT_CONTEXT.md | head -5

   # Header separators should exist
   grep -E '^\|[-: |]+\|$' PROJECT_CONTEXT.md
   ```

3. **Validate links:**
   ```bash
   # Extract all markdown links
   grep -oE '\[([^\]]+)\]\(([^)]+)\)' PROJECT_CONTEXT.md > links.txt

   # Check internal links exist
   # (manual verification or scripted)
   ```

**Pass Criteria:**
- ✅ Markdown lint passes
- ✅ Tables properly formatted
- ✅ Links are valid

---

### 5. JSON Schema Validation (Optional)

**Objective:** If a JSON export is generated, validate against schema.

**Steps:**

1. **Convert to JSON** (if applicable):
   ```bash
   # Use custom parser or jq to extract structured data
   python scripts/md-to-json.py PROJECT_CONTEXT.md > PROJECT_CONTEXT.json
   ```

2. **Validate against schema:**
   ```bash
   # Using JSON schema validator
   jsonschema -i PROJECT_CONTEXT.json outputs/project-context-json-schema.json
   ```

**Pass Criteria:**
- ✅ JSON is well-formed
- ✅ Passes schema validation

---

## Optional Export Formats

### Export to JSON

**Purpose:** Machine-readable format for RAG systems, API consumption, or automation.

**Script Example:**
```python
#!/usr/bin/env python3
# scripts/export-to-json.py

import re
import json

def parse_project_context(md_file):
    with open(md_file, 'r') as f:
        content = f.read()

    # Extract structured data
    data = {
        "metadata": extract_metadata(content),
        "identity": extract_section(content, "IDENTITY"),
        "technology_stack": extract_section(content, "TECHNOLOGY_STACK"),
        "dependencies": extract_dependencies(content),
        "architecture": extract_section(content, "ARCHITECTURE"),
        # ... extract other sections
    }

    return data

def extract_section(content, section_tag):
    pattern = rf'\[SECTION:{section_tag}\](.*?)(?=\[SECTION:|$)'
    match = re.search(pattern, content, re.DOTALL)
    if match:
        return match.group(1).strip()
    return None

# ... implementation details

if __name__ == "__main__":
    import sys
    md_file = sys.argv[1]
    data = parse_project_context(md_file)
    print(json.dumps(data, indent=2))
```

**Usage:**
```bash
python scripts/export-to-json.py PROJECT_CONTEXT.md > PROJECT_CONTEXT.json
```

---

### Export to YAML

**Purpose:** Human-readable structured format for configuration management.

**Script Example:**
```python
#!/usr/bin/env python3
# scripts/export-to-yaml.py

import yaml
from export_to_json import parse_project_context

if __name__ == "__main__":
    import sys
    md_file = sys.argv[1]
    data = parse_project_context(md_file)
    print(yaml.dump(data, default_flow_style=False, sort_keys=False))
```

**Usage:**
```bash
python scripts/export-to-yaml.py PROJECT_CONTEXT.md > PROJECT_CONTEXT.yaml
```

---

### Generate Summary Report

**Purpose:** Quick-reference single-page summary for humans.

**Output Example:**
```markdown
# Project Summary: MyProject

**Type:** Web API
**Language:** Node.js 20
**Framework:** Express 4.19
**Dependencies:** 47 total (12 production, 35 dev)
**Test Coverage:** 78%
**API Endpoints:** 23
**Last Updated:** 2025-11-17

## Quick Links
- [Full Context](PROJECT_CONTEXT.md)
- [Architecture Diagram](PROJECT_CONTEXT.md#architecture)
- [API Surface](PROJECT_CONTEXT.md#api-surface)
- [Configuration](PROJECT_CONTEXT.md#configuration)

## Health Status
- ✅ Tests passing
- ✅ Dependencies up-to-date
- ⚠️ Known issues: 3 (see KNOWN_ISSUES.md)
```

---

## Postprocessing Checklist

Use this checklist before marking PROJECT_CONTEXT as validated:

### Structure & Compliance
- [ ] All template sections present
- [ ] Section tags preserved
- [ ] Heading hierarchy correct
- [ ] No unauthorized sections added

### Content Quality
- [ ] No placeholder text ([TODO], [TBD])
- [ ] All file paths verified (spot check 10)
- [ ] Versions are exact
- [ ] Evidence-based (no speculation)
- [ ] Code blocks have language tags

### Security
- [ ] No API keys or tokens
- [ ] No passwords or credentials
- [ ] No database connection strings
- [ ] No private keys
- [ ] Internal hostnames redacted (if required)
- [ ] Redaction rules followed

### Format
- [ ] Markdown lint passes
- [ ] Tables properly formatted
- [ ] Links are valid
- [ ] Images load correctly (if any)

### Optional Exports
- [ ] JSON export generated (if needed)
- [ ] JSON validates against schema
- [ ] YAML export generated (if needed)
- [ ] Summary report generated (if needed)

---

## Integration with CI/CD

### GitHub Actions Example

```yaml
name: Validate PROJECT_CONTEXT

on:
  pull_request:
    paths:
      - 'PROJECT_CONTEXT.md'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Validate Markdown
        run: |
          npm install -g markdownlint-cli
          markdownlint PROJECT_CONTEXT.md

      - name: Check for Secrets
        run: |
          ./scripts/check-secrets.sh PROJECT_CONTEXT.md

      - name: Validate Structure
        run: |
          python scripts/validate-structure.py PROJECT_CONTEXT.md

      - name: Generate JSON Export
        run: |
          python scripts/export-to-json.py PROJECT_CONTEXT.md > PROJECT_CONTEXT.json

      - name: Validate JSON Schema
        run: |
          npm install -g ajv-cli
          ajv validate -s outputs/project-context-json-schema.json -d PROJECT_CONTEXT.json
```

---

## Error Handling

### Common Validation Failures

**Missing Sections:**
- **Error:** Template section not found in output
- **Action:** Re-run Cartographer with correct template
- **Prevention:** Use outputTemplate config variable

**Placeholder Text Detected:**
- **Error:** [TODO] or [TBD] found in output
- **Action:** Review and complete missing sections
- **Prevention:** Ensure Cartographer has access to all needed files

**Secret Leaked:**
- **Error:** API key or password detected in output
- **Action:** Immediately remove from file and git history
- **Prevention:** Use git-secrets, check .env.example vs .env

**Invalid Markdown:**
- **Error:** Markdown linter errors
- **Action:** Fix formatting issues (usually table alignment or code blocks)
- **Prevention:** Use automated formatting tools

---

## Best Practices

1. **Automate Validation:** Run postprocessing in CI/CD for every PROJECT_CONTEXT change
2. **Version Control:** Commit PROJECT_CONTEXT.md alongside code
3. **Regular Updates:** Re-run Cartographer when major dependencies or architecture changes
4. **Export Artifacts:** Generate JSON exports for downstream automation
5. **Security First:** Always run secret scanning before committing
6. **Peer Review:** Have human review for first-time generation or major changes
7. **Document Exceptions:** If validation fails but output is acceptable, document why in commit message

---

## Scripts Directory Structure

Recommended scripts for postprocessing automation:

```
scripts/
├── validate-structure.py      # Check template compliance
├── check-secrets.sh           # Scan for leaked secrets
├── export-to-json.py          # Convert MD → JSON
├── export-to-yaml.py          # Convert MD → YAML
├── generate-summary.py        # Create summary report
└── validate-evidence.py       # Verify file paths exist
```

---

This postprocessing playbook ensures that PROJECT_CONTEXT.md outputs are high-quality, secure, and ready for production use by humans and machines alike.
